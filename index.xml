<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>404EngineerNotFound</title><link>https://deepskandpal.github.io/</link><description>Recent content on 404EngineerNotFound</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 03 May 2025 22:38:57 +0530</lastBuildDate><atom:link href="https://deepskandpal.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>System Prompts that I found usefull</title><link>https://deepskandpal.github.io/tech-writings/prompts/</link><pubDate>Sat, 03 May 2025 22:38:57 +0530</pubDate><guid>https://deepskandpal.github.io/tech-writings/prompts/</guid><description>&lt;p>Below is the list of system prompts i use for different tasks with gemini 2.5 pro model&lt;/p>
&lt;h1 id="for-learning-dsa">For learning DSA&lt;/h1>
&lt;p>&lt;code>you are an expert DSA expert who specializes in teaching how to track coding problems you have written books and specializes in coaching those students who run away from DSA. Your ability to boil down even complex problems and concepts into very simple intuitive first principals based explanation makes you the best in the trade . You are starting a new course based on the book elements of programming interview in python. You will cover each chapters core topics and also cover each section and the core problems in that chapter. &lt;/code>&lt;/p></description></item><item><title>Sequential Test and Adaptive Experimental Design</title><link>https://deepskandpal.github.io/papershelf/msprt/</link><pubDate>Sun, 27 Apr 2025 19:30:00 +0000</pubDate><guid>https://deepskandpal.github.io/papershelf/msprt/</guid><description/></item><item><title>The Matrix Calculus You Need For Deep Learning</title><link>https://deepskandpal.github.io/papershelf/maths/</link><pubDate>Sun, 27 Apr 2025 19:30:00 +0000</pubDate><guid>https://deepskandpal.github.io/papershelf/maths/</guid><description/></item><item><title/><link>https://deepskandpal.github.io/stories/ek-kahani-aisibhi/</link><pubDate>Fri, 25 Apr 2025 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/stories/ek-kahani-aisibhi/</guid><description/></item><item><title>Multi Processing , Multi Threading, AsyncIO: A Guide to Python Concurrency for Data Scientists</title><link>https://deepskandpal.github.io/tech-writings/concurrency-ds/</link><pubDate>Fri, 25 Apr 2025 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/tech-writings/concurrency-ds/</guid><description>&lt;p>&lt;strong>The problem : Help! My Python SDXL Script Isn&amp;rsquo;t Faster with Asyncio/Threading/Multiprocessing. Why?&lt;/strong>&lt;/p>
&lt;p>You&amp;rsquo;ve built a cool script, maybe generating image variations with SDXL (&lt;a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0">Stable Diffusion XL model&lt;/a>) like one of our engineers. It works, but it&amp;rsquo;s slow. You think, &amp;ldquo;I know! Parallelism!&amp;rdquo; You try asyncio, then multithreading, maybe even multiprocessing. But&amp;hellip; nothing speeds up significantly, or you just hit weird errors, especially in your Jupyter Notebook. Sounds familiar?&lt;/p>
&lt;p>This is a common hurdle when data science tasks meet heavier computation. Let&amp;rsquo;s demystify Python&amp;rsquo;s asyncio, multithreading, and multiprocessing, touching on the underlying Operating System (OS) ideas and Python&amp;rsquo;s infamous GIL.&lt;/p></description></item><item><title>About</title><link>https://deepskandpal.github.io/about/</link><pubDate>Mon, 14 Apr 2025 22:29:36 +0530</pubDate><guid>https://deepskandpal.github.io/about/</guid><description>&lt;p>Hi—I’m Deepanshu Kandpal. Over the past eight years I’ve jumped between e‑commerce, telecom, consulting and cybersecurity, always chasing that moment when clever code becomes real‑world impact. Right now at KnowBe4 I’m building LLM‑powered agents that sniff out threats and automate responses at scale. Before that at Farfetch I helped grow an A/B testing platform to handle 100K+ queries a day across 300 TB of data—learning firsthand how to coordinate agile teams across continents. On the side, I tinker with LangChef, my open‑source framework for LLM experimentation. I actually got my start as an iOS developer at Jio, crafting AI assistants that now handle over 3 million queries daily and take a huge load off call‑center teams.&lt;/p></description></item><item><title>Current Workout Plan</title><link>https://deepskandpal.github.io/fitness-log/workout-plan/</link><pubDate>Thu, 01 Aug 2024 10:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/fitness-log/workout-plan/</guid><description>&lt;p>&lt;strong>Important Notes Before You Start:&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Warm-up:&lt;/strong> Always perform a 5-10 minute warm-up before each workout (light cardio, dynamic stretches).&lt;/li>
&lt;li>&lt;strong>Cool-down:&lt;/strong> Always perform a 5-10 minute cool-down after each workout (static stretching).&lt;/li>
&lt;li>&lt;strong>Weight Column:&lt;/strong> This column is for &lt;em>you&lt;/em> to fill in each week. Start with a weight that challenges you to complete the target reps with &lt;em>good form&lt;/em>. If you can easily complete the highest number of reps listed (e.g., 12 reps) for all sets, increase the weight slightly the following week. &lt;em>Form is always more important than the amount of weight.&lt;/em>&lt;/li>
&lt;li>&lt;strong>Progression (Weeks 1-8):&lt;/strong> Focus on &lt;strong>Progressive Overload&lt;/strong>. Gradually increase weight, reps, sets, or intensity, or decrease rest time.&lt;/li>
&lt;li>&lt;strong>Listen to Your Body:&lt;/strong> Stop if you feel pain. Take extra rest days if needed.&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>&lt;strong>Workout Plan: Weeks 1-8&lt;/strong>&lt;/p></description></item><item><title>Two Sum</title><link>https://deepskandpal.github.io/dsa-log/two-sum/</link><pubDate>Wed, 01 May 2024 10:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/dsa-log/two-sum/</guid><description>&lt;h2 id="problem-description-optional-summary">Problem Description (Optional Summary)&lt;/h2>
&lt;p>Given an array of integers &lt;code>nums&lt;/code> and an integer &lt;code>target&lt;/code>, return indices of the two numbers such that they add up to &lt;code>target&lt;/code>.&lt;/p>
&lt;h2 id="solution-approach">Solution Approach&lt;/h2>
&lt;p>Use a hash map (dictionary in Python) to store numbers encountered so far and their indices. For each number, check if &lt;code>target - current_number&lt;/code> exists in the hash map. If it does, we found the pair. Otherwise, add the current number and its index to the map.&lt;/p></description></item><item><title>Arrays</title><link>https://deepskandpal.github.io/dsa-concepts/arrays/</link><pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/dsa-concepts/arrays/</guid><description>&lt;h2 id="introduction-to-arrays">Introduction to Arrays&lt;/h2>
&lt;p>An array is a fundamental data structure used to store a collection of elements, typically of the same data type, in contiguous memory locations. Each element is identified by an index or a key.&lt;/p>
&lt;h2 id="key-characteristics">Key Characteristics&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Fixed Size (Static Arrays):&lt;/strong> In many languages, traditional arrays have a fixed size defined at creation.&lt;/li>
&lt;li>&lt;strong>Dynamic Size (Dynamic Arrays/Lists):&lt;/strong> Languages like Python offer dynamic arrays (lists) that can grow or shrink.&lt;/li>
&lt;li>&lt;strong>Contiguous Memory:&lt;/strong> Elements are stored next to each other, allowing for efficient index-based access.&lt;/li>
&lt;li>&lt;strong>O(1) Access:&lt;/strong> Accessing an element by its index is typically a constant time operation.&lt;/li>
&lt;li>&lt;strong>O(n) Insertion/Deletion (Worst Case):&lt;/strong> Inserting or deleting elements in the middle may require shifting subsequent elements.&lt;/li>
&lt;/ul>
&lt;h2 id="common-operations--complexity">Common Operations &amp;amp; Complexity&lt;/h2>
&lt;ul>
&lt;li>Access (by index): O(1)&lt;/li>
&lt;li>Search (linear): O(n)&lt;/li>
&lt;li>Insertion (at end, amortized for dynamic): O(1)&lt;/li>
&lt;li>Insertion (at beginning/middle): O(n)&lt;/li>
&lt;li>Deletion (at end): O(1)&lt;/li>
&lt;li>Deletion (at beginning/middle): O(n)&lt;/li>
&lt;/ul>
&lt;h2 id="use-cases">Use Cases&lt;/h2>
&lt;ul>
&lt;li>Storing lists of items.&lt;/li>
&lt;li>Implementing other data structures (stacks, queues).&lt;/li>
&lt;li>Lookup tables (when used with indices).&lt;/li>
&lt;/ul></description></item><item><title>Hashing</title><link>https://deepskandpal.github.io/dsa-concepts/hashing/</link><pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/dsa-concepts/hashing/</guid><description>&lt;h2 id="introduction-to-hashing">Introduction to Hashing&lt;/h2>
&lt;p>Hashing is the process of converting an input item (key) into a fixed-size value, typically an integer index, using a hash function. This index is then used to place or locate the item in a data structure, most commonly a hash table (hash map or dictionary).&lt;/p>
&lt;h2 id="key-concepts">Key Concepts&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Hash Function:&lt;/strong> A function that maps keys to indices. A good hash function should be fast to compute and distribute keys uniformly across the available indices.&lt;/li>
&lt;li>&lt;strong>Hash Table:&lt;/strong> A data structure that uses a hash function to map keys to values for efficient lookups.&lt;/li>
&lt;li>&lt;strong>Collisions:&lt;/strong> Occur when two different keys map to the same index.&lt;/li>
&lt;li>&lt;strong>Collision Resolution:&lt;/strong> Strategies to handle collisions, such as:
* &lt;strong>Separate Chaining:&lt;/strong> Each index points to a linked list (or other structure) containing all keys that hash to that index.
* &lt;strong>Open Addressing (Probing):&lt;/strong> If an index is occupied, probe for the next available slot (linear probing, quadratic probing, double hashing).&lt;/li>
&lt;/ul>
&lt;h2 id="common-operations--complexity-average-case-for-hash-tables">Common Operations &amp;amp; Complexity (Average Case for Hash Tables)&lt;/h2>
&lt;ul>
&lt;li>Insertion: O(1)&lt;/li>
&lt;li>Deletion: O(1)&lt;/li>
&lt;li>Search: O(1)&lt;/li>
&lt;li>&lt;em>(Worst Case for all can be O(n) if collisions are poorly handled or hash function is bad)&lt;/em>&lt;/li>
&lt;/ul>
&lt;h2 id="use-cases">Use Cases&lt;/h2>
&lt;ul>
&lt;li>Implementing dictionaries/hash maps.&lt;/li>
&lt;li>Database indexing.&lt;/li>
&lt;li>Caching.&lt;/li>
&lt;li>Checking for duplicates.&lt;/li>
&lt;/ul></description></item><item><title>Linked Lists</title><link>https://deepskandpal.github.io/dsa-concepts/linked-lists/</link><pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/dsa-concepts/linked-lists/</guid><description/></item><item><title>Attention Is All You Need</title><link>https://deepskandpal.github.io/papershelf/attention-all-u-need/</link><pubDate>Sat, 27 Apr 2024 19:30:00 +0000</pubDate><guid>https://deepskandpal.github.io/papershelf/attention-all-u-need/</guid><description/></item><item><title>Infinite Retrieval: Attention Enhanced LLMs in Long-Context Processing</title><link>https://deepskandpal.github.io/papershelf/infinit-retrevial-attention/</link><pubDate>Sat, 27 Apr 2024 19:30:00 +0000</pubDate><guid>https://deepskandpal.github.io/papershelf/infinit-retrevial-attention/</guid><description/></item><item><title>One-Minute Video Generation with Test-Time Training</title><link>https://deepskandpal.github.io/papershelf/ttt-layer-for-video-generation/</link><pubDate>Mon, 15 Apr 2024 19:30:00 +0000</pubDate><guid>https://deepskandpal.github.io/papershelf/ttt-layer-for-video-generation/</guid><description>&lt;p>&lt;a href="https://test-time-training.github.io/video-dit/">Website&lt;/a>&lt;/p>
&lt;h2 id="tldr">TLDR;&lt;/h2>
&lt;p>They tackled long video generation by replacing expensive global attention with efficient local attention, and bridging the gaps between local segments using novel TTT layers. These TTT layers act like RNNs but have a much smarter, adaptive hidden state (a neural network that learns on-the-fly during generation). This allows them to capture long-range dependencies and complex dynamics better than traditional RNNs, leading to more coherent minute-long videos, albeit with some remaining artifacts and efficiency challenges.&lt;/p></description></item><item><title>Animal GPT</title><link>https://deepskandpal.github.io/creations/animal-gpt/</link><pubDate>Wed, 20 Mar 2024 14:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/creations/animal-gpt/</guid><description>&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>This is a brief summary of the example project, highlighting its main purpose or key feature. It&amp;rsquo;s used on the card display.&lt;/p>
&lt;h2 id="details">Details&lt;/h2>
&lt;p>Here you can write a full description of the project.&lt;/p>
&lt;ul>
&lt;li>Explain the goals.&lt;/li>
&lt;li>Describe the technologies used.&lt;/li>
&lt;li>Discuss challenges faced and solutions implemented.&lt;/li>
&lt;li>Include code snippets or further images if relevant using Markdown.&lt;/li>
&lt;/ul>
&lt;pre tabindex="0">&lt;code class="language-go-html" data-lang="go-html">{{/* Example code snippet */}}
&lt;/code>&lt;/pre></description></item><item><title>Hands-On Large Language Models: Language Understanding and Generation</title><link>https://deepskandpal.github.io/bookshelf/hands-on-llm/</link><pubDate>Sun, 10 Mar 2024 12:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/hands-on-llm/</guid><description/></item><item><title>The Hundred-Page Language Models Book</title><link>https://deepskandpal.github.io/bookshelf/the-lm-book/</link><pubDate>Sun, 10 Mar 2024 12:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/the-lm-book/</guid><description/></item><item><title>Harry Potter and the Chamber of Secrets</title><link>https://deepskandpal.github.io/bookshelf/hp-2/</link><pubDate>Thu, 22 Feb 2024 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/hp-2/</guid><description/></item><item><title>Harry Potter and the Deathly Hallows</title><link>https://deepskandpal.github.io/bookshelf/hp-7/</link><pubDate>Thu, 22 Feb 2024 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/hp-7/</guid><description/></item><item><title>Harry Potter and the Half-Blood Prince</title><link>https://deepskandpal.github.io/bookshelf/hp-6/</link><pubDate>Thu, 22 Feb 2024 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/hp-6/</guid><description/></item><item><title>Harry Potter and the Order of the Phoenix</title><link>https://deepskandpal.github.io/bookshelf/hp-5/</link><pubDate>Thu, 22 Feb 2024 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/hp-5/</guid><description/></item><item><title>Harry Potter and the Prisoner of Azkaban</title><link>https://deepskandpal.github.io/bookshelf/hp-3/</link><pubDate>Thu, 22 Feb 2024 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/hp-3/</guid><description/></item><item><title>Harry Potter and the Prisoner of Azkaban</title><link>https://deepskandpal.github.io/bookshelf/hp-4/</link><pubDate>Thu, 22 Feb 2024 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/hp-4/</guid><description/></item><item><title>Elon Musk: Tesla, SpaceX, and the Quest for a Fantastic Future</title><link>https://deepskandpal.github.io/bookshelf/elon-musk/</link><pubDate>Tue, 20 Feb 2024 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/elon-musk/</guid><description/></item><item><title>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, 2nd Edition</title><link>https://deepskandpal.github.io/bookshelf/hands-on-ml/</link><pubDate>Tue, 20 Feb 2024 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/hands-on-ml/</guid><description/></item><item><title>Harry Potter and the Philosopher's StoneS</title><link>https://deepskandpal.github.io/bookshelf/hp-1/</link><pubDate>Tue, 20 Feb 2024 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/hp-1/</guid><description/></item><item><title>Shoe Dog</title><link>https://deepskandpal.github.io/bookshelf/shoe-dog/</link><pubDate>Tue, 20 Feb 2024 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/shoe-dog/</guid><description/></item><item><title>STEVE JOBS</title><link>https://deepskandpal.github.io/bookshelf/steve-jobs/</link><pubDate>Tue, 20 Feb 2024 11:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/steve-jobs/</guid><description/></item><item><title>Accelerating India's Development: A State-Led Roadmap for Effective Governance</title><link>https://deepskandpal.github.io/bookshelf/accelerating-india/</link><pubDate>Mon, 15 Jan 2024 10:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/accelerating-india/</guid><description/></item><item><title>Good To Great</title><link>https://deepskandpal.github.io/bookshelf/good-to-great/</link><pubDate>Mon, 15 Jan 2024 10:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/good-to-great/</guid><description/></item><item><title>Interpretable Machine Learning</title><link>https://deepskandpal.github.io/bookshelf/interpretable-machine-learning/</link><pubDate>Mon, 15 Jan 2024 10:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/interpretable-machine-learning/</guid><description/></item><item><title>Priceless: the myth of fair value (and how to take advantage of it)</title><link>https://deepskandpal.github.io/bookshelf/priceless/</link><pubDate>Mon, 15 Jan 2024 10:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/priceless/</guid><description/></item><item><title>The Beginning of Infinity</title><link>https://deepskandpal.github.io/bookshelf/begin-infinity/</link><pubDate>Mon, 15 Jan 2024 10:00:00 +0000</pubDate><guid>https://deepskandpal.github.io/bookshelf/begin-infinity/</guid><description/></item></channel></rss>