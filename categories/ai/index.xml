<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on 404EngineerNotFound</title><link>https://deepskandpal.github.io/categories/ai/</link><description>Recent content in AI on 404EngineerNotFound</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 08 Jun 2025 01:01:23 +0530</lastBuildDate><atom:link href="https://deepskandpal.github.io/categories/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity</title><link>https://deepskandpal.github.io/papershelf/read/illusion-of-thinking/</link><pubDate>Sun, 08 Jun 2025 01:01:23 +0530</pubDate><guid>https://deepskandpal.github.io/papershelf/read/illusion-of-thinking/</guid><description>&lt;p>At its heart, &amp;ldquo;The Illusion of Thinking,&amp;rdquo; is about trying to genuinely understand how well these new &amp;ldquo;Large Reasoning Models&amp;rdquo; (LRMs) actually &lt;em>reason&lt;/em>. You&amp;rsquo;ve probably heard about models that show their &amp;ldquo;thinking steps&amp;rdquo; before giving an answer, like with Chain-of-Thought. They often do better on benchmarks, which is exciting. But we felt that just looking at the final answer on standard math or coding tests wasn&amp;rsquo;t telling the whole story.&lt;/p></description></item><item><title>One-Minute Video Generation with Test-Time Training</title><link>https://deepskandpal.github.io/papershelf/read/ttt-layer-for-video-generation/</link><pubDate>Mon, 15 Apr 2024 19:30:00 +0000</pubDate><guid>https://deepskandpal.github.io/papershelf/read/ttt-layer-for-video-generation/</guid><description>&lt;p>&lt;a href="https://test-time-training.github.io/video-dit/">Website&lt;/a>&lt;/p>
&lt;h2 id="tldr">TLDR;&lt;/h2>
&lt;p>They tackled long video generation by replacing expensive global attention with efficient local attention, and bridging the gaps between local segments using novel TTT layers. These TTT layers act like RNNs but have a much smarter, adaptive hidden state (a neural network that learns on-the-fly during generation). This allows them to capture long-range dependencies and complex dynamics better than traditional RNNs, leading to more coherent minute-long videos, albeit with some remaining artifacts and efficiency challenges.&lt;/p></description></item></channel></rss>