<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>RAG on 404EngineerNotFound</title><link>https://deepskandpal.github.io/categories/rag/</link><description>Recent content in RAG on 404EngineerNotFound</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 27 Apr 2024 19:30:00 +0000</lastBuildDate><atom:link href="https://deepskandpal.github.io/categories/rag/index.xml" rel="self" type="application/rss+xml"/><item><title>Infinite Retrieval: Attention Enhanced LLMs in Long-Context Processing</title><link>https://deepskandpal.github.io/papershelf/read/infinit-retrevial-attention/</link><pubDate>Sat, 27 Apr 2024 19:30:00 +0000</pubDate><guid>https://deepskandpal.github.io/papershelf/read/infinit-retrevial-attention/</guid><description>&lt;h2 id="paper"&gt;&lt;strong&gt;Paper: &amp;ldquo;Infinite Retrieval: Attention Enhanced LLMs in Long-Context Processing&amp;rdquo;&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Link:&lt;/strong&gt; &lt;a href="https://arxiv.org/abs/2502.12962"&gt;https://arxiv.org/abs/2502.12962&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Date:&lt;/strong&gt; Based on arXiv pattern, likely February 2025 (very recent)
&lt;strong&gt;Domain:&lt;/strong&gt; Retrieval-Augmented Generation (RAG) and Long-Context Processing&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;âœ… Completed&lt;/strong&gt; - This paper focuses on enhancing LLMs&amp;rsquo; long-context processing capabilities through improved attention and retrieval mechanisms using a sliding window approach with internal attention-based retrieval.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="why-this-paper-matters"&gt;&lt;strong&gt;Why This Paper Matters&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Long-context processing remains one of the key challenges in modern LLMs. This work likely addresses:&lt;/p&gt;</description></item></channel></rss>