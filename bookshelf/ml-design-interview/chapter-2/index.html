<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>404EngineerNotFound</title><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css integrity="sha512-SnH5WK+bZxgPHs44uWIX+LLJAJ9/2PkPKZ5QiAj6Ta86w+fsb2TkcmfRyVX3pBnMFcV7oQPJkl9QevSCWr3W6A==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.31/dist/flexsearch.bundle.js></script><script src=https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js></script></head><body>\<header><nav><div class=logo><a href=/>404EngineerNotFound</a></div><ul class=main-nav><li class="nav-item has-dropdown"><a href=#>Writings <i class="fas fa-caret-down fa-xs"></i></a><ul class=dropdown-menu><li class=dropdown-item><a href=/stories/>Stories</a></li><li class=dropdown-item><a href=/thoughts/>Thoughts</a></li><li class=dropdown-item><a href=/fitness-log/>Fitness Log</a></li></ul></li><li class="nav-item has-dropdown"><a href=#>Tech Lab <i class="fas fa-caret-down fa-xs"></i></a><ul class=dropdown-menu><li class=dropdown-item><a href=/papershelf/>Papershelf</a></li><li class=dropdown-item><a href=/creations/>Creations</a></li><li class=dropdown-item><a href=/dsa-log/>DSA Log</a></li><li class=dropdown-item><a href=/tech-writings/>Technical Writings</a></li></ul></li><li class=nav-item><a href=/bookshelf/>Bookshelf</a></li><li class=nav-item><a href=/about/>About</a></li></ul><div class=search-container><input type=search id=search-input placeholder=Search...>
<i class="fa fa-search"></i></div></nav><div id=search-results-container><ul id=search-results></ul></div></header><main><div class=single-content-wrapper><aside class=article-sidebar><nav><h4>On this page</h4><nav id=TableOfContents><ul><li><a href=#candidate-generation---finding-the-haystack-needles>Candidate Generation - Finding the Haystack Needles</a><ul><li><a href=#1-content-based-filtering>1. Content-Based Filtering</a></li><li><a href=#2-collaborative-filtering>2. Collaborative Filtering</a></li><li><a href=#3-combining-candidate-generators-the-multi-source-approach>3. Combining Candidate Generators: The Multi-Source Approach</a></li></ul></li><li><a href=#ordering-the-candidates-with-precision>Ordering the Candidates with Precision</a><ul><li><a href=#1-pointwise-ranking-the-classificationregression-approach>1. Pointwise Ranking: The &ldquo;Classification/Regression&rdquo; Approach</a></li><li><a href=#2-pairwise-ranking-the-relative-order-approach>2. Pairwise Ranking: The &ldquo;Relative Order&rdquo; Approach</a></li><li><a href=#3-listwise-ranking-the-holistic-list-approach>3. Listwise Ranking: The &ldquo;Holistic List&rdquo; Approach</a></li><li><a href=#putting-it-all-together-for-the-interview>Putting it all together for the interview</a></li></ul></li><li><a href=#re-ranking---the-final-polish>Re-ranking - The Final Polish</a><ul><li><a href=#1-filtering-and-hard-constraints>1. Filtering and Hard Constraints</a></li><li><a href=#2-promoting-diversity>2. Promoting Diversity</a></li><li><a href=#3-injecting-business-logic--boosting>3. Injecting Business Logic & Boosting</a></li><li><a href=#4-fairness-and-bias-mitigation>4. Fairness and Bias Mitigation</a></li><li><a href=#putting-it-all-together-for-the-interview-1>Putting it all together for the interview</a></li></ul></li><li><a href=#position-bias---the-rich-get-richer>Position Bias - &ldquo;The Rich Get Richer&rdquo;</a></li><li><a href=#impression-discounting-linkedin-pymk-case-study>Impression Discounting (LinkedIn PYMK Case Study)</a></li><li><a href=#calibration---is-your-80-really-an-80>Calibration - &ldquo;Is your 80% really an 80%?&rdquo;</a></li><li><a href=#nonstationary-problem-exploration-vs-exploitation-and-airbnbs-lessons>Nonstationary Problem, Exploration vs. Exploitation, and Airbnb&rsquo;s Lessons</a></li></ul></nav></nav></aside><article class=book-single><h1>Chapter 2: Common Recommendation System Components.</h1><span class=reading-time><em>25 min read</em></span><div class=book-details><div class=book-content><p>This chapter is the heart of the book and arguably the most important for many ML system design interviews, as recommendation systems are a classic and recurring design question. We&rsquo;ll break down the three key stages: <strong>Candidate Generation</strong>, <strong>Ranking</strong>, and <strong>Re-ranking</strong>.</p><h2 id=candidate-generation---finding-the-haystack-needles>Candidate Generation - Finding the Haystack Needles</h2><p>This is the first and arguably most critical stage of a large-scale recommender.</p><ul><li><p><strong>Book&rsquo;s Core Idea (Timeless):</strong> You cannot possibly score and rank every single item in your corpus (e.g., all 500 million videos on YouTube) for every user in real time. The goal of candidate generation (also called retrieval or sourcing) is to narrow down this massive set to a few hundred or a few thousand &ldquo;pretty good&rdquo; candidates, quickly and cheaply. The book presents the two classic approaches:</p><ol><li><strong>Content-Based Filtering:</strong> &ldquo;Show me more items like the ones I already like.&rdquo;</li><li><strong>Collaborative Filtering:</strong> &ldquo;Show me items that people similar to me like.&rdquo;</li></ol></li><li><p><strong>The 2024+ Perspective:</strong> The concepts remain the same, but the implementation has evolved significantly. Let&rsquo;s break down the modern methods for each.</p></li></ul><hr><h3 id=1-content-based-filtering>1. Content-Based Filtering</h3><ul><li><p><strong>How it Works (Then):</strong> The book&rsquo;s example of a binary feature matrix for apps is a good starting point. You represent items as vectors of their attributes (category, price, etc.) and find items with similar vectors to the ones a user has interacted with.</p></li><li><p><strong>How it Works (Now - The 2024+ Way):</strong> This is now almost exclusively done using <strong>deep learning embeddings</strong>.</p><ol><li><strong>Generate Item Embeddings:</strong> You use a powerful pre-trained model to create a rich, semantic vector for every item. For a movie, this might involve feeding its title, synopsis, and genre into a Transformer-based text model (like BERT). For a product, you might feed its image into a vision model (like CLIP) and its description into a text model, then concatenate the resulting vectors.</li><li><strong>Generate a User Profile:</strong> You look at the items a user has recently interacted with positively (e.g., liked, purchased). You fetch the pre-computed embeddings for these items.</li><li><strong>Find Similar Items:</strong> You can now find candidates in two ways:<ul><li><strong>Average User Profile:</strong> Average the embeddings of the items the user liked to create a &ldquo;user profile&rdquo; vector. Then, use an ANN index to find other item embeddings that are close to this profile vector.</li><li><strong>Item-to-Item Similarity:</strong> For each item the user recently liked, find the &ldquo;top K&rdquo; most similar items directly from your ANN index. This is the core of Amazon&rsquo;s &ldquo;Customers who bought this item also bought&mldr;&rdquo; feature.</li></ul></li></ol></li><li><p><strong>Diagram (Modern Content-Based Retrieval):</strong></p></li></ul><pre tabindex=0><code class=language-mermaid data-lang=mermaid>graph TD
    subgraph &#34;Offline: Item Embedding Generation&#34;
        Item_Data[&#34;Item Metadata&lt;br/&gt;(Text, Images)&#34;] --&gt; Embedding_Model(&#34;Pre-trained&lt;br/&gt;Transformer/Vision Model&#34;) --&gt; Item_Embeddings[(&#34;Item Embeddings&#34;)]
        Item_Embeddings --&gt; ANN_Index[(&#34;Vector DB / FAISS&#34;)]
    end

    subgraph &#34;Online: User Request&#34;
        User_History[&#34;User&#39;s recent likes&lt;br/&gt;(Item A, Item B)&#34;] --&gt; Fetch_Embeds{&#34;Fetch Embeddings&lt;br/&gt;for A and B&#34;}
        Fetch_Embeds -- &#34;Item_A_vec, Item_B_vec&#34; --&gt; User_Profile(&#34;Create User Profile&lt;br/&gt;e.g., Average vectors&#34;)
        User_Profile --&gt; ANN_Index
        ANN_Index --&gt; Candidates[&#34;Candidate Items&#34;]
    end

    style ANN_Index fill:#cde4ff
</code></pre><ul><li><strong>Interview Phrasing:</strong> &ldquo;For content-based candidate generation, we will pre-compute a rich semantic embedding for every item in our catalog using a pre-trained foundation model. When a user is active, we can generate a real-time user profile by averaging the embeddings of items they&rsquo;ve recently interacted with. We then query our vector index with this profile vector to retrieve hundreds of content-similar candidates.&rdquo;</li></ul><hr><h3 id=2-collaborative-filtering>2. Collaborative Filtering</h3><ul><li><p><strong>Book&rsquo;s Core Idea (Timeless):</strong> This method doesn&rsquo;t care about the content of the items at all. It relies solely on the user-item interaction matrix. The core idea is to find users with similar taste and recommend items that one has seen but the other has not. The book explains the classic approach: <strong>Matrix Factorization</strong>.</p><ul><li><strong>Matrix Factorization:</strong> You have a giant, sparse matrix of users and items. The goal is to &ldquo;factorize&rdquo; this into two smaller, dense matrices: a <strong>user-embedding matrix</strong> (U) and an <strong>item-embedding matrix</strong> (V). The dot product of a user&rsquo;s embedding and an item&rsquo;s embedding should approximate the rating that user would give that item.</li></ul></li><li><p><strong>How it Works (Now - The 2024+ Way):</strong> The principle is identical, but the implementation is now the <strong>Two-Tower Model</strong> we&rsquo;ve discussed extensively. A two-tower model <em>is</em> the modern, deep learning-based way of doing collaborative filtering. Instead of using a classic algorithm like ALS (Alternating Least Squares) to find the embeddings, you train two deep neural networks with a contrastive loss. This is far more powerful because the towers can ingest rich features about the user and item, not just their IDs.</p></li><li><p><strong>Diagram (Matrix Factorization vs. Two-Tower):</strong></p></li></ul><pre tabindex=0><code class=language-mermaid data-lang=mermaid>graph TD
    subgraph &#34;Classic Matrix Factorization&#34;
        direction LR
        A[&#34;Sparse User-Item&lt;br/&gt;Interaction Matrix&#34;] --&gt; Factorize{&#34;Factorization Algorithm&lt;br/&gt;(e.g., ALS, SGD)&#34;}
        Factorize --&gt; U[(&#34;User Embeddings&#34;)]
        Factorize --&gt; V[(&#34;Item Embeddings&#34;)]
    end
    
    subgraph &#34;Modern Collaborative Filtering (Two-Tower Model)&#34;
        direction LR
        B[&#34;Raw User-Item Interactions&lt;br/&gt;+ Rich Features&#34;] --&gt; Train{&#34;Train Two Towers&lt;br/&gt;with Contrastive Loss&#34;}
        Train --&gt; U2[(&#34;User Embeddings&#34;)]
        Train --&gt; V2[(&#34;Item Embeddings&#34;)]
    end

    style B fill:#dff0d8
</code></pre><hr><h3 id=3-combining-candidate-generators-the-multi-source-approach>3. Combining Candidate Generators: The Multi-Source Approach</h3><ul><li><strong>Book&rsquo;s Core Idea (Timeless):</strong> You don&rsquo;t just use one method. A real-world recommender system is a blend of many candidate generators. The YouTube example in the book is perfect: they have one generator based on topic similarity (content-based), another based on co-watch patterns (collaborative filtering), and likely many others.</li><li><strong>The 2024+ Perspective:</strong> This is a crucial point to make in an interview. A senior candidate designs a system, not just a single model.</li><li><strong>Why it&rsquo;s important:</strong><ul><li><strong>Diversity:</strong> Different generators find different kinds of items. A collaborative filtering source might find popular, trending items, while a content-based source can find niche items perfectly tailored to a user&rsquo;s specific taste.</li><li><strong>Cold Start Problem:</strong> For a brand new user with no history, collaborative filtering is impossible. For this user, you would rely entirely on other sources, like &ldquo;most popular items,&rdquo; content-based recommendations based on their sign-up info (age/country), or recommendations based on the first item they click on.</li><li><strong>Resiliency:</strong> If one candidate generator goes down, the others can still provide recommendations, making the system more robust.</li></ul></li><li><strong>Diagram (The Funnel):</strong></li></ul><pre tabindex=0><code class=language-mermaid data-lang=mermaid>graph TD
    subgraph &#34;Candidate Generation Stage&#34;
        CG1[&#34;Content-Based&lt;br/&gt;Item-to-Item&#34;]
        CG2[&#34;Collaborative Filtering&lt;br/&gt;Two-Tower Model&#34;]
        CG3[&#34;Trending / Most Popular&#34;]
        CG4[&#34;New Items / Exploration&#34;]
    end
    
    CG1 --&gt; Merge{&#34;Merge &amp; Deduplicate&#34;}
    CG2 --&gt; Merge
    CG3 --&gt; Merge
    CG4 --&gt; Merge
    
    Merge --&gt; Candidates[&#34;~500-1000 Candidates&#34;]
    Candidates --&gt; Ranking_Stage(&#34;Next Stage: Ranking&#34;)

    style Merge fill:#fff0b3
</code></pre><ul><li><strong>Interview Phrasing:</strong> &ldquo;Our system won&rsquo;t rely on a single source for candidates. I&rsquo;d propose a multi-source retrieval strategy. We&rsquo;d have at least three main generators: one based on <strong>collaborative filtering</strong> using a two-tower model to find items popular with similar users; a second using <strong>content-based</strong> item-to-item similarity for niche recommendations; and a third for <strong>business logic</strong>, such as boosting new or trending items. We would then merge and de-duplicate the outputs from all sources before passing the combined candidate set to the ranking model. This ensures diversity and robustness.&rdquo;</li></ul><p>Excellent. We&rsquo;ve successfully narrowed down a sea of billions of items to a manageable pool of ~500 candidates. Now, we enter the <strong>Ranking</strong> stage. This is where we get serious about precision.</p><h2 id=ordering-the-candidates-with-precision>Ordering the Candidates with Precision</h2><ul><li><p><strong>Book&rsquo;s Core Idea (Timeless):</strong> The goal of the ranking stage is to take the ~500 candidates from the retrieval stage and score them with a much more powerful, precise, and computationally expensive model. Because we are only dealing with a few hundred items per user, we can now afford to use rich features that were too slow for the retrieval stage. The output is a finely ordered list of the top ~10-20 items to actually display to the user.</p></li><li><p><strong>The 2024+ Perspective:</strong> The core purpose remains the same. The main evolution is in the complexity and type of models used and the richness of the features they can handle. The distinction between a fast retrieval model and a slower, more accurate ranking model is a fundamental pattern in large-scale ML.</p></li></ul><p>Let&rsquo;s break down the different ways to frame the ranking problem.</p><hr><h3 id=1-pointwise-ranking-the-classificationregression-approach>1. Pointwise Ranking: The &ldquo;Classification/Regression&rdquo; Approach</h3><ul><li><strong>Book&rsquo;s Core Idea (Timeless):</strong> This is the most common and straightforward approach. You treat each candidate item <em>independently</em>. The model&rsquo;s job is to predict a score for a single <code>(user, item)</code> pair.</li><li><strong>Intuition:</strong> You are essentially building a model that answers a direct question for each candidate:<ul><li><strong>Classification:</strong> &ldquo;What is the probability that this user will click on this item?&rdquo; (Output a score from 0 to 1).</li><li><strong>Regression:</strong> &ldquo;How many minutes will this user watch this video?&rdquo; (Output a numerical score).</li></ul></li><li>The final ranked list is created by simply sorting all the candidates by their independent scores in descending order.</li><li><strong>Diagram:</strong></li></ul><pre tabindex=0><code class=language-mermaid data-lang=mermaid>graph TD
    subgraph &#34;Input&#34;
        U[&#34;User Features&lt;br/&gt;(age, country, user_embedding)&#34;]
        I[&#34;Item Features&lt;br/&gt;(category, price, item_embedding)&#34;]
        C[&#34;Context Features&lt;br/&gt;(time of day, device)&#34;]
    end
    
    U &amp; I &amp; C --&gt; R_Model{&#34;Pointwise Ranking Model&lt;br/&gt;(e.g., XGBoost, Deep Neural Network)&#34;}
    R_Model --&gt; Score(&#34;Predicted Score&lt;br/&gt;e.g., p(click) = 0.083&#34;)
    
    subgraph &#34;Process for each candidate&#34;
        Candidate1 --&gt; R_Model --&gt; Score1(&#34;0.083&#34;)
        Candidate2 --&gt; R_Model --&gt; Score2(&#34;0.012&#34;)
        Candidate3 --&gt; R_Model --&gt; Score3(&#34;0.157&#34;)
    end
    
    subgraph &#34;Final List&#34;
        Sort{&#34;Sort by Score&#34;} --&gt; FinalList(&#34;1. Candidate 3&lt;br/&gt;2. Candidate 1&lt;br/&gt;3. Candidate 2&#34;)
    end
    
    Score1 &amp; Score2 &amp; Score3 --&gt; Sort
</code></pre><ul><li><strong>The 2024+ Perspective:</strong> This is still the workhorse of most industrial ranking systems. The models have become more powerful (often large Transformer-based networks that can handle raw text and cross-feature interactions), but the core idea of scoring each item individually is the same. Its strength is simplicity and the ability to directly optimize for a clear business metric like <code>p(click)</code>.</li></ul><hr><h3 id=2-pairwise-ranking-the-relative-order-approach>2. Pairwise Ranking: The &ldquo;Relative Order&rdquo; Approach</h3><ul><li><strong>Book&rsquo;s Core Idea (Timeless):</strong> This approach reframes the problem. Instead of predicting an absolute score for each item, the model learns to predict which item in a <em>pair</em> is better. The model is trained on pairs of documents, <code>(Item A, Item B)</code>, and the label is <code>1</code> if A should be ranked higher than B, and <code>0</code> otherwise. The book&rsquo;s example of <strong>RankNet</strong> is the classic algorithm for this.</li><li><strong>Intuition:</strong> The model learns a function <code>f(item)</code> that produces a score. It is trained so that if <code>A</code> is better than <code>B</code>, then <code>f(A) > f(B)</code>. The actual values of the scores don&rsquo;t matter, only their relative order.</li><li><strong>Equation (RankNet&rsquo;s Core):</strong><ol><li>Take two items, A and B, and get their scores from the model: <code>s_a = f(A)</code> and <code>s_b = f(B)</code>.</li><li>Calculate the difference: <code>s_ab = s_a - s_b</code>.</li><li>Pass this through a sigmoid function to get a probability that A is better than B: <code>P_ab = sigmoid(s_ab)</code>.</li><li>The loss is simply the cross-entropy between this predicted probability and the ground-truth label (e.g., <code>1</code> if A was actually clicked and B was not).</li></ol></li><li><strong>Pros & Cons:</strong><ul><li><strong>Pro:</strong> Can be more effective at directly optimizing for ranking metrics like NDCG. It&rsquo;s focused only on getting the order right.</li><li><strong>Con (The big one):</strong> The number of possible pairs is quadratic (<code>n²</code>), which can be computationally explosive. You need to be clever about which pairs you train on. More importantly, the final scores are not calibrated probabilities; you can&rsquo;t interpret a score of <code>0.8</code> as an 80% click probability, which is often a business requirement.</li></ul></li></ul><hr><h3 id=3-listwise-ranking-the-holistic-list-approach>3. Listwise Ranking: The &ldquo;Holistic List&rdquo; Approach</h3><ul><li><strong>Book&rsquo;s Core Idea (Outdated/Academic):</strong> The book mentions this as the third formulation. This approach attempts to solve the &ldquo;perfect&rdquo; ranking problem by taking the <em>entire list</em> of candidates as input to the model at once and training it to directly output the optimal ordering.</li><li><strong>Intuition:</strong> The model learns to consider the context of the whole list. For example, it might learn not to show two very similar-looking items next to each other to promote diversity.</li><li><strong>The 2024+ Perspective:</strong> While theoretically the most powerful, listwise approaches are <strong>rarely used in large-scale industrial systems</strong>.<ul><li><strong>Why?</strong> The model architecture becomes incredibly complex (it needs to handle a variable-length list of items as input), and the computational cost during serving is often prohibitively high. The complexity and cost usually do not justify the marginal gains over a well-tuned pointwise model.</li></ul></li><li><strong>Interview Phrasing:</strong> You should acknowledge its existence but frame it as an academic/research topic. &ldquo;While pointwise ranking is the most common industrial approach, there are also pairwise and listwise formulations. Listwise methods, which optimize the entire ranked list at once, are theoretically powerful for capturing cross-item interactions like diversity, but they are often too computationally expensive for real-time, low-latency production systems. A more practical way to handle diversity is in a re-ranking stage.&rdquo;</li></ul><hr><h3 id=putting-it-all-together-for-the-interview>Putting it all together for the interview</h3><p>Your go-to strategy should be to propose a <strong>pointwise</strong> ranker, as it&rsquo;s the most practical and widely used.</p><p><strong>Senior-Level Phrasing for Ranking Design:</strong></p><p>&ldquo;For the ranking stage, we&rsquo;ll take the ~500 candidates from our retrieval models and score them using a more powerful model. I would propose a <strong>pointwise ranking approach</strong>, where we train a deep neural network to predict the probability of a click for each (user, item) pair.</p><ul><li><p><strong>Features:</strong> This model can afford to use much richer and more expensive-to-compute features than the retrieval towers. We would include:</p><ul><li><strong>User features:</strong> long-term user profile embedding, real-time features like <code>clicks_in_last_hour</code>.</li><li><strong>Item features:</strong> detailed item content embedding, popularity statistics.</li><li><strong>Cross-features:</strong> We&rsquo;d explicitly compute interactions between the user and item embeddings (e.g., dot product, element-wise product) to feed into the network, helping it learn personalized relevance.</li></ul></li><li><p><strong>Model:</strong> A standard multi-layer perceptron (MLP) is a strong baseline. To improve, we could incorporate attention layers to better weigh the importance of different features.</p></li><li><p><strong>Objective:</strong> We would train this as a binary classifier using a standard <strong>cross-entropy (log loss)</strong>.</p></li><li><p><strong>Serving:</strong> At inference time, we score each of the 500 candidates independently and sort them by their predicted <code>p(click)</code> to generate the final list shown to the user.&rdquo;</p></li></ul><p>Excellent. We&rsquo;ve retrieved a few hundred candidates and ranked them precisely. We&rsquo;re almost ready to show the final list to the user. But there&rsquo;s one final, optional stage where we can apply crucial business logic and heuristics: <strong>Re-ranking</strong>.</p><h2 id=re-ranking---the-final-polish>Re-ranking - The Final Polish</h2><ul><li><p><strong>Book&rsquo;s Core Idea (Timeless):</strong> Re-ranking is a post-processing step that takes the beautifully ordered list from the ranking model and makes final adjustments. It&rsquo;s not about learning complex patterns; it&rsquo;s about enforcing hard constraints, promoting diversity, injecting business rules, and ensuring fairness.</p></li><li><p><strong>Why have a separate stage?</strong> Why not just teach the ranking model all these rules?</p><ul><li><strong>Simplicity & Speed:</strong> Many business rules are complex to learn and would bloat the ranking model. A simple <code>if/then</code> rule applied to the top 20 candidates is much faster and more reliable than trying to teach a neural network the same concept.</li><li><strong>Agility:</strong> Business rules change frequently. &ldquo;This week, we want to boost all items from brand X.&rdquo; It&rsquo;s far easier and safer to change a rule in a simple re-ranking service than to retrain and redeploy the entire core ranking model.</li></ul></li></ul><hr><h3 id=1-filtering-and-hard-constraints>1. Filtering and Hard Constraints</h3><ul><li><strong>What it is:</strong> The most basic function of re-ranking is to remove items that should <em>never</em> be shown.</li><li><strong>Examples:</strong><ul><li><strong>Already Seen:</strong> Remove items the user has seen in their current session to avoid repetition.</li><li><strong>User-Blocked Content:</strong> Remove content from creators the user has explicitly blocked or muted.</li><li><strong>Not Safe for Work (NSFW):</strong> Filter out inappropriate content.</li><li><strong>Inventory Check:</strong> For an e-commerce site, remove items that just went out of stock in the last few seconds.</li></ul></li><li><strong>How it&rsquo;s done:</strong> This is typically a series of simple lookups against blocklists or caches.</li></ul><h3 id=2-promoting-diversity>2. Promoting Diversity</h3><ul><li><strong>The Problem:</strong> Your ranking model might be <em>too</em> good. If a user clicks on one video about &ldquo;golden retrievers,&rdquo; the ranker might score 19 other golden retriever videos very highly. Showing a list of nearly identical items is a boring and unhelpful user experience. This is called over-specialization.</li><li><strong>The Solution:</strong> The re-ranker can enforce diversity. A common algorithm is <strong>Maximal Marginal Relevance (MMR)</strong>, though a simpler heuristic is often used in practice.</li><li><strong>Intuition (Simple Heuristic):</strong><ol><li>Start with your top-ranked item and add it to the final list.</li><li>Now, iterate down your original ranked list from position 2. For each candidate:</li><li>Calculate its similarity to all items <em>already in the final list</em>.</li><li>If it&rsquo;s too similar to any of them (e.g., same category, high embedding similarity), penalize its score or skip it.</li><li>If it&rsquo;s sufficiently different, add it to the final list.</li><li>Repeat until your final list has the desired number of items (e.g., 10).</li></ol></li><li><strong>Diagram (Diversity in action):</strong></li></ul><pre tabindex=0><code class=language-mermaid data-lang=mermaid>graph TD
    subgraph &#34;Ranker Output (Over-specialized)&#34;
        R1(&#34;1. Golden Retriever Video A&#34;)
        R2(&#34;2. Golden Retriever Video B&#34;)
        R3(&#34;3. Corgi Video X&#34;)
        R4(&#34;4. Golden Retriever Video C&#34;)
        R5(&#34;5. Labrador Video Y&#34;)
    end

    subgraph &#34;Re-ranking Logic&#34;
        A{&#34;Start with #1&#34;} --&gt; F1(&#34;Final List: GR_A&#34;)
        B{&#34;Consider #2&#34;} -- &#34;Too similar to GR_A&#34; --&gt; Skip1(&#34;Penalize/Skip&#34;)
        C{&#34;Consider #3&#34;} -- &#34;Sufficiently different&#34; --&gt; F2(&#34;Final List: GR_A, Corgi_X&#34;)
        D{&#34;Consider #4&#34;} -- &#34;Too similar to GR_A&#34; --&gt; Skip2(&#34;Penalize/Skip&#34;)
        E{&#34;Consider #5&#34;} -- &#34;Sufficiently different&#34; --&gt; F3(&#34;Final List: GR_A, Corgi_X, Lab_Y&#34;)
    end

    subgraph &#34;Final Displayed List (Diverse)&#34;
        D1(&#34;1. Golden Retriever Video A&#34;)
        D2(&#34;2. Corgi Video X&#34;)
        D3(&#34;3. Labrador Video Y&#34;)
    end
</code></pre><h3 id=3-injecting-business-logic--boosting>3. Injecting Business Logic & Boosting</h3><ul><li><strong>What it is:</strong> This is where the business and product teams get to influence the final output directly.</li><li><strong>Examples:</strong><ul><li><strong>Freshness:</strong> Boost the score of content published in the last 24 hours to promote newness (as mentioned in the book for YouTube).</li><li><strong>Merchandising:</strong> A business rule states, &ldquo;For the next week, boost the score of all Samsung products by 20%.&rdquo;</li><li><strong>Promote High-Margin Items:</strong> Boost the score of items that have a higher profit margin for the company.</li><li><strong>Exploration:</strong> Randomly boost a few new items that have no interaction data yet, to help them get initial exposure and escape the cold-start problem. This is a simple form of exploration.</li></ul></li></ul><h3 id=4-fairness-and-bias-mitigation>4. Fairness and Bias Mitigation</h3><ul><li><strong>The Problem:</strong> The ranking model, trained on historical data, might have learned societal biases. For example, a job recommendation system might unintentionally rank qualified female candidates lower for a &ldquo;Software Engineer&rdquo; role if the training data was historically male-dominated.</li><li><strong>The Solution:</strong> The re-ranking stage is a practical place to intervene.<ul><li><strong>Fairness Constraints:</strong> After scoring, you can audit the top <code>k</code> results. If you find that the gender or racial representation is skewed compared to the pool of qualified candidates, you can re-rank the list to achieve a more equitable representation.</li><li><strong>Example:</strong> For a &ldquo;CEO&rdquo; query on a people search, if the top 20 results are all male, the re-ranker might identify qualified female candidates from lower in the list (e.g., position 35) and promote them into the top 20.</li></ul></li><li><strong>The 2024+ Perspective:</strong> This is an extremely active and important area. While re-ranking is a powerful tool for &ldquo;post-processing&rdquo; fairness, modern approaches also try to address this earlier in the pipeline, for example, by adding fairness constraints directly into the training objective of the ranking model.</li></ul><hr><h3 id=putting-it-all-together-for-the-interview-1>Putting it all together for the interview</h3><p><strong>Senior-Level Phrasing for Re-ranking Design:</strong></p><p>&ldquo;After our deep learning model produces a ranked list of ~500 candidates, I would add a lightweight <strong>re-ranking stage</strong> to apply final business logic before displaying the top 10. This stage would be responsible for several key tasks:</p><ol><li><strong>Filtering:</strong> It would first perform hard filtering to remove any items the user has already seen in this session or content from blocked creators.</li><li><strong>Diversity:</strong> To avoid showing a list of nearly identical items, it would apply a heuristic to ensure category-level diversity. For example, we wouldn&rsquo;t place more than two items from the same sub-category in the top 10.</li><li><strong>Business Boosting:</strong> It would apply dynamic boosts based on business rules, such as increasing the score for content that is less than 24 hours old to promote freshness, or for content that is part of a current marketing campaign.</li><li><strong>Exploration:</strong> To help new items gather data, we would give a small score boost to a fraction of candidates that have very few impressions.</li></ol><p>This modular approach is more agile and maintainable than trying to bake all this complex and frequently changing logic directly into the main ranking model.&rdquo;</p><p>This concludes our deep dive into the three core components of a recommendation system. You now have a comprehensive, modern view of candidate generation, ranking, and re-ranking.</p><p>Of course. These are fantastic topics to cover, as they represent the &ldquo;real world&rdquo; challenges of ML that go beyond textbook models. Mastering these concepts is what truly distinguishes a senior candidate. It shows you&rsquo;ve dealt with the messy reality of production systems.</p><p>Let&rsquo;s dive into each one.</p><hr><h2 id=position-bias---the-rich-get-richer>Position Bias - &ldquo;The Rich Get Richer&rdquo;</h2><ul><li><p><strong>Book&rsquo;s Core Idea (Timeless):</strong> Users are inherently biased towards clicking on items at the top of a list, regardless of their quality. The item at position 1 gets more attention than the item at position 2, and so on.</p></li><li><p><strong>The Vicious Cycle (The Problem):</strong></p><ol><li>Your model places Item A at position 1.</li><li>Because it&rsquo;s at position 1, it gets a lot of clicks.</li><li>You collect this click data to retrain your model.</li><li>The model sees &ldquo;Oh, Item A gets a ton of clicks! It must be extremely relevant.&rdquo;</li><li>The retrained model learns to rank Item A even higher, reinforcing the bias. Eventually, your model just learns to rank popular items at the top, and new or potentially more relevant items never get a chance to be seen. The model is learning the bias, not the true relevance.</li></ol></li><li><p><strong>Solution 1: Use Position as a Feature (The most common approach)</strong></p><ul><li><strong>How it works:</strong> During training, you add <code>position</code> as a feature to your model. The model learns that this feature is highly correlated with the click target. For instance, it learns <code>p(click | position=1) = 0.2</code>, but <code>p(click | position=10) = 0.01</code>. It effectively learns to disentangle the inherent &ldquo;quality&rdquo; of an item from the &ldquo;bonus&rdquo; it gets just by being at a certain position.</li><li><strong>The Magic Trick (At Inference):</strong> When you use the model for serving, you want to find the <em>true</em> relevance, stripped of the position bias. To do this, you feed <strong>a constant value for the position feature</strong> for all candidates. For example, you ask the model: &ldquo;What would the click probability be for each of these items if they were <em>all</em> shown at position 1?&rdquo; You then rank by this &ldquo;unbiased&rdquo; score.</li></ul></li><li><p><strong>Solution 2: Inverse Propensity Score (IPS)</strong></p><ul><li><strong>How it works:</strong> This is a data-weighting approach. You re-weight your training examples to correct for the bias. Clicks on items at lower positions (which are rare and thus strong signals of relevance) are given a higher weight in the loss function than clicks on items at the top.</li><li><strong>Equation:</strong> <code>Weight = 1 / p(shown_at_position_i)</code>. <code>p(shown_at_position_i)</code> is the &ldquo;propensity score.&rdquo; An item at position 10 has a low propensity, so its weight is high.</li><li><strong>2024+ Perspective:</strong> While statistically pure, IPS can suffer from high variance if some propensities are very small. The &ldquo;Position as a Feature&rdquo; method is generally more robust and more common in industry.</li></ul></li><li><p><strong>Interview Phrasing:</strong> &ldquo;Position bias is a critical issue we must address. In our training data, user clicks are heavily influenced by an item&rsquo;s rank. To mitigate this, I would include <strong>position as a feature</strong> in our ranking model. The model will learn to associate the position with click propensity. Then, during inference, we will neutralize this bias by passing a fixed position value (e.g., position 1) for all candidates, allowing us to rank based on the model&rsquo;s estimate of true, position-independent relevance.&rdquo;</p></li></ul><hr><h2 id=impression-discounting-linkedin-pymk-case-study>Impression Discounting (LinkedIn PYMK Case Study)</h2><ul><li><strong>The Problem:</strong> In the &ldquo;People You May Know&rdquo; (PYMK) feature, LinkedIn shows you a list of potential connections. A user might see the same person recommended to them day after day. They don&rsquo;t accept the connection, but they also don&rsquo;t explicitly dismiss them. The model, seeing no negative signal, keeps recommending the same person because their raw relevance score is high. This creates a stale and annoying user experience.</li><li><strong>The Solution: Impression Discounting.</strong> This is a brilliant, practical heuristic applied at the re-ranking stage.<ul><li><strong>Intuition:</strong> &ldquo;The more times I&rsquo;ve shown you this person and you <em>haven&rsquo;t</em> connected, the less likely you are to ever connect. I should penalize this person&rsquo;s score each time I show them to you.&rdquo;</li></ul></li><li><strong>How it works (Conceptual):</strong><ol><li>Maintain a persistent impression counter for each <code>(viewer_id, candidate_id)</code> pair.</li><li>The ranking model calculates a raw relevance score, <code>S_raw</code>.</li><li>The re-ranker fetches the impression count, <code>N</code>, for this pair.</li><li>It calculates a discount factor, <code>d(N)</code>, which is a function that increases with <code>N</code>. For example, <code>d(N) = 1 / (1 + α*N)</code>.</li><li>The final score is <code>S_final = S_raw * d(N)</code>.</li></ol></li><li><strong>Diagram:</strong></li></ul><pre tabindex=0><code class=language-mermaid data-lang=mermaid>graph TD
    subgraph &#34;Day 1&#34;
        Model_Score(&#34;Model Score for Person X = 0.9&#34;) --&gt; Final_Score1(&#34;Final Score = 0.9&lt;br/&gt;Show to User&#34;)
        Imp_Store1[(&#34;Impression Store:&lt;br/&gt;User to X: 0&#34;)]
    end

    subgraph &#34;Day 2 (User did not connect)&#34;
        Imp_Store2[(&#34;Impression Store:&lt;br/&gt;User to X: 1&#34;)]
        Model_Score2(&#34;Model Score for Person X = 0.9&#34;) --&gt; Discount1{&#34;Discount Factor d(1)&#34;}
        Imp_Store2 --&gt; Discount1
        Discount1 --&gt; Final_Score2(&#34;Final Score = 0.75&lt;br/&gt;Show to User&#34;)
    end

    subgraph &#34;Day 3 (User did not connect)&#34;
        Imp_Store3[(&#34;Impression Store:&lt;br/&gt;User to X: 2&#34;)]
        Model_Score3(&#34;Model Score for Person X = 0.9&#34;) --&gt; Discount2{&#34;Discount Factor d(2)&#34;}
        Imp_Store3 --&gt; Discount2
        Discount2 --&gt; Final_Score3(&#34;Final Score = 0.5&lt;br/&gt;Maybe don&#39;t show...&#34;)
    end

    style Imp_Store1 fill:#cde4ff
    style Imp_Store2 fill:#cde4ff
    style Imp_Store3 fill:#cde4ff
</code></pre><ul><li><strong>Interview Phrasing:</strong> &ldquo;To prevent recommendation staleness, where we repeatedly show the same candidates a user isn&rsquo;t engaging with, I would implement an <strong>impression discounting</strong> system in the re-ranking stage. We would persist an impression count for each user-candidate pair. The final ranking score would be the model&rsquo;s raw score multiplied by a discount factor that is inversely proportional to the number of times the item has been shown without a positive interaction. This keeps the feed fresh and improves user experience.&rdquo;</li></ul><hr><h2 id=calibration---is-your-80-really-an-80>Calibration - &ldquo;Is your 80% really an 80%?&rdquo;</h2><ul><li><strong>Book&rsquo;s Core Idea (Timeless):</strong> Calibration is about ensuring that a model&rsquo;s predicted probability corresponds to the true probability in the real world. If your model predicts <code>p(click) = 0.8</code> for a set of 100 ads, then roughly 80 of those ads should actually get clicked.</li><li><strong>Why it&rsquo;s crucial:</strong><ul><li><strong>Ad Auctions:</strong> If you use your <code>p(click)</code> to calculate an expected value for bidding (<code>eCPM = p(click) * advertiser_bid</code>), an uncalibrated probability will lead to systematically over- or under-bidding, costing millions.</li><li><strong>Business Decisions:</strong> If you tell a user &ldquo;There is an 80% chance of rain,&rdquo; they expect it to rain 8 out of 10 times. A miscalibrated model erodes trust.</li></ul></li><li><strong>Why models become miscalibrated:</strong><ol><li><strong>Downsampling:</strong> As discussed, if you downsample your negative class, your model&rsquo;s outputs will be artificially high.</li><li><strong>Model Architecture:</strong> Some models, like SVMs or even modern neural networks with ReLU activations, are not inherently designed to produce calibrated probabilities. They are designed to maximize rank-ordering (AUC).</li></ol></li><li><strong>Solution: Post-processing.</strong> You take the raw output of your trained model and pass it through a simple, secondary calibration model.<ul><li><strong>Platt Scaling:</strong> Fits a logistic regression model on top of your primary model&rsquo;s scores. It&rsquo;s simple and effective.</li><li><strong>Isotonic Regression:</strong> A more powerful, non-parametric method that fits a piecewise-constant, non-decreasing function. It&rsquo;s more flexible than Platt scaling but requires more data.</li><li><strong>The Downsampling Correction Formula (from the book):</strong> <code>calibrated_p = p / (p + (1-p)/w)</code>. This is a specific form of calibration required when you downsample.</li></ul></li><li><strong>Interview Phrasing:</strong> &ldquo;While our ranking model is optimized for a metric like AUC, its raw probability outputs may not be well-calibrated, which is critical for our ad auction bidding logic. After training the main ranker, I would add a <strong>post-processing calibration step</strong>. We would train an Isotonic Regression model on a held-out validation set, which maps the model&rsquo;s output scores to true, empirically observed probabilities. This ensures that our downstream bidding systems can trust the predictions.&rdquo;</li></ul><hr><h2 id=nonstationary-problem-exploration-vs-exploitation-and-airbnbs-lessons>Nonstationary Problem, Exploration vs. Exploitation, and Airbnb&rsquo;s Lessons</h2><p>These final topics are about the dynamic, ever-changing nature of real-world ML.</p><ul><li><p><strong>Nonstationary Problem (Concept Drift):</strong> The world changes. User tastes change, new products are introduced, slang evolves. A model trained on 2023 data will perform poorly on 2024 data because the underlying <code>p(y|x)</code> has shifted.</p><ul><li><strong>Solution:</strong> <strong>Constant retraining.</strong> This is the primary industrial solution. Your entire data pipeline and training infrastructure must be automated and robust enough to retrain your model frequently (daily, or even hourly for very dynamic systems). This is why the infrastructure discussions we had earlier are so important.</li></ul></li><li><p><strong>Exploration vs. Exploitation:</strong> This is a fundamental trade-off.</p><ul><li><strong>Exploitation:</strong> Use the current best model and knowledge to show the user what you <em>think</em> they will like most. (e.g., recommend the video with the highest predicted watch time). This maximizes short-term metrics.</li><li><strong>Exploration:</strong> Show the user something new and uncertain to gather information. (e.g., recommend a video from a brand new channel). This might hurt short-term metrics but is essential for long-term discovery and preventing your system from becoming a boring echo chamber.</li><li><strong>Solution:</strong> <strong>Epsilon-Greedy</strong> is the simplest approach. 99% of the time, you &ldquo;exploit.&rdquo; 1% of the time (epsilon), you pick a random item to &ldquo;explore.&rdquo; More advanced solutions involve <strong>Multi-Armed Bandits (Thompson Sampling, UCB)</strong> which provide a more intelligent way to balance this trade-off.</li></ul></li><li><p><strong>Airbnb&rsquo;s Lessons (&ldquo;Deep Learning is NOT a drop-in replacement&rdquo;):</strong> This is a story of humility and respect for baselines.</p><ol><li><strong>The Story:</strong> The Airbnb team had a well-performing Gradient Boosted Decision Tree (GBDT) model. They tried to replace it with a fancy deep learning model and found that it performed <em>no better</em> or even worse initially.</li><li><strong>The Lesson:</strong> Deep learning models are not magic. They have a huge number of hyperparameters to tune (architecture, learning rate, initializations). A well-tuned GBDT on well-crafted features is an incredibly strong baseline. Beating it requires careful, systematic work, not just swapping model types.</li><li><strong>The book&rsquo;s specifics are gold:</strong> They found that features that worked well for the GBDT didn&rsquo;t work well for the NN, and vice-versa. They had to re-do their feature engineering. They had to experiment with different learning rates and weight initializations.</li></ol></li><li><p><strong>Interview Phrasing (combining these concepts):</strong> &ldquo;A key challenge in this system is that user preferences are <strong>nonstationary</strong>. To combat this drift, we must build a pipeline for frequent, automated retraining. This also ties into the <strong>exploration/exploitation</strong> trade-off. To ensure we are constantly learning about new items and tastes, I would introduce an &rsquo;epsilon-greedy&rsquo; exploration strategy in our re-ranking stage. This is a lesson learned from industry case studies like Airbnb&rsquo;s, which showed that even powerful deep learning models can fail if they aren&rsquo;t constantly fed fresh, diverse data and that beating a strong GBDT baseline requires careful, iterative engineering, not just a model swap.&rdquo;</p></li></ul></div></div></article></div></main><footer><p>&copy; 2025 Deepanshu Kandpal</p></footer><a id=scrollTopBtn title="Go to top"><i class="fa-solid fa-arrow-up"></i></a>
<script src=/js/search.js></script><script>var mybutton=document.getElementById("scrollTopBtn");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?mybutton.classList.add("show"):mybutton.classList.remove("show")}mybutton.onclick=function(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script><script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll("code.language-mermaid");e.forEach(function(e,t){const n=document.createElement("div");n.className="mermaid",n.textContent=e.textContent,n.id="mermaid-"+t,e.parentNode.parentNode.replaceChild(n,e.parentNode)}),mermaid.initialize({startOnLoad:!0,theme:"default",themeVariables:{primaryColor:"#4a90e2",primaryTextColor:"#333",primaryBorderColor:"#4a90e2",lineColor:"#333"}}),mermaid.init()})</script></body></html>