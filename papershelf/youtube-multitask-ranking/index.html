<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>404EngineerNotFound</title><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css integrity="sha512-SnH5WK+bZxgPHs44uWIX+LLJAJ9/2PkPKZ5QiAj6Ta86w+fsb2TkcmfRyVX3pBnMFcV7oQPJkl9QevSCWr3W6A==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.31/dist/flexsearch.bundle.js></script><script src=https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js></script></head><body>\<header><nav><div class=logo><a href=/>404EngineerNotFound</a></div><ul class=main-nav><li class="nav-item has-dropdown"><a href=#>Writings <i class="fas fa-caret-down fa-xs"></i></a><ul class=dropdown-menu><li class=dropdown-item><a href=/stories/>Stories</a></li><li class=dropdown-item><a href=/thoughts/>Thoughts</a></li><li class=dropdown-item><a href=/fitness-log/>Fitness Log</a></li></ul></li><li class="nav-item has-dropdown"><a href=#>Tech Lab <i class="fas fa-caret-down fa-xs"></i></a><ul class=dropdown-menu><li class=dropdown-item><a href=/papershelf/>Papershelf</a></li><li class=dropdown-item><a href=/creations/>Creations</a></li><li class=dropdown-item><a href=/dsa-log/>DSA Log</a></li><li class=dropdown-item><a href=/tech-writings/>Technical Writings</a></li></ul></li><li class=nav-item><a href=/bookshelf/>Bookshelf</a></li><li class=nav-item><a href=/about/>About</a></li></ul><div class=search-container><input type=search id=search-input placeholder=Search...>
<i class="fa fa-search"></i></div></nav><div id=search-results-container><ul id=search-results></ul></div></header><main><div class=single-content-wrapper><aside class=article-sidebar><nav><h4>On this page</h4><nav id=TableOfContents><ul><li><ul><li><a href=#paper><strong>Paper: &ldquo;Recommending What Video to Watch Next: A Multitask Ranking System&rdquo;</strong></a></li><li><a href=#abstract><strong>Abstract:</strong></a></li><li><a href=#1-introduction><strong>1. Introduction</strong></a><ul><li><a href=#11-context--motivation><strong>1.1 Context & Motivation</strong></a></li><li><a href=#12-challenges-in-multi-objective-recommendation><strong>1.2 Challenges in Multi-Objective Recommendation</strong></a></li></ul></li><li><a href=#2-multi-task-learning-architecture><strong>2. Multi-Task Learning Architecture</strong></a><ul><li><a href=#21-problem-formulation><strong>2.1 Problem Formulation</strong></a></li><li><a href=#22-multi-gate-mixture-of-experts-mmoe><strong>2.2 Multi-gate Mixture-of-Experts (MMoE)</strong></a></li><li><a href=#23-expert-and-gate-design><strong>2.3 Expert and Gate Design</strong></a></li></ul></li><li><a href=#3-handling-selection-bias><strong>3. Handling Selection Bias</strong></a><ul><li><a href=#31-the-selection-bias-problem><strong>3.1 The Selection Bias Problem</strong></a></li><li><a href=#32-wide--deep-learning-for-bias-correction><strong>3.2 Wide & Deep Learning for Bias Correction</strong></a></li><li><a href=#33-additional-bias-mitigation-techniques><strong>3.3 Additional Bias Mitigation Techniques</strong></a></li></ul></li><li><a href=#4-production-system-design><strong>4. Production System Design</strong></a><ul><li><a href=#41-serving-architecture><strong>4.1 Serving Architecture</strong></a></li><li><a href=#42-training-infrastructure><strong>4.2 Training Infrastructure</strong></a></li><li><a href=#43-ab-testing-and-evaluation><strong>4.3 A/B Testing and Evaluation</strong></a></li></ul></li><li><a href=#5-experimental-results><strong>5. Experimental Results</strong></a><ul><li><a href=#51-offline-evaluation><strong>5.1 Offline Evaluation</strong></a></li><li><a href=#52-online-evaluation><strong>5.2 Online Evaluation</strong></a></li><li><a href=#53-bias-mitigation-results><strong>5.3 Bias Mitigation Results</strong></a></li></ul></li><li><a href=#6-lessons-learned-and-best-practices><strong>6. Lessons Learned and Best Practices</strong></a><ul><li><a href=#61-multi-task-learning-insights><strong>6.1 Multi-Task Learning Insights</strong></a></li><li><a href=#62-production-deployment-lessons><strong>6.2 Production Deployment Lessons</strong></a></li><li><a href=#63-bias-mitigation-learnings><strong>6.3 Bias Mitigation Learnings</strong></a></li></ul></li><li><a href=#7-impact-and-significance><strong>7. Impact and Significance</strong></a><ul><li><a href=#71-academic-contributions><strong>7.1 Academic Contributions</strong></a></li><li><a href=#72-industry-impact><strong>7.2 Industry Impact</strong></a></li><li><a href=#73-research-directions-enabled><strong>7.3 Research Directions Enabled</strong></a></li></ul></li><li><a href=#8-future-work-and-limitations><strong>8. Future Work and Limitations</strong></a><ul><li><a href=#81-current-limitations><strong>8.1 Current Limitations</strong></a></li><li><a href=#82-potential-improvements><strong>8.2 Potential Improvements</strong></a></li><li><a href=#83-emerging-challenges><strong>8.3 Emerging Challenges</strong></a></li></ul></li></ul></li></ul></nav></nav></aside><article class=paper-single><div class=paper-categories>Filed under:
<span class=category-pill>Recommender Systems</span></div><h1>Recommending What Video to Watch Next: A Multitask Ranking System</h1><span class=reading-time><em>8 min read</em></span><div class=paper-content><h2 id=paper><strong>Paper: &ldquo;Recommending What Video to Watch Next: A Multitask Ranking System&rdquo;</strong></h2><p><strong>Authors:</strong> Zhe Zhao, Lichan Hong, Li Wei, Jilin Chen, Aniruddh Nath, Shawn Andrews, Aditee Kumthekar, Maheswaran Sathiamoorthy, Xinyang Yi, Ed Chi (Google)</p><p><strong>Conference:</strong> RecSys 2019</p><h2 id=abstract><strong>Abstract:</strong></h2><p>This paper presents YouTube&rsquo;s large-scale multi-objective ranking system for &ldquo;watch next&rdquo; recommendations, serving over one billion users. The system simultaneously optimizes for multiple engagement objectives (clicks, watch time, shares, etc.) using a Multi-gate Mixture-of-Experts (MMoE) architecture. Key innovations include techniques to handle selection bias in training data and methods to balance multiple objectives in a production environment.</p><p><strong>Key Results:</strong></p><ul><li>Deployed MMoE architecture significantly outperforms single-task and shared-bottom multi-task models</li><li>Handles multiple objectives simultaneously: engagement prediction, satisfaction prediction, and other behavioral signals</li><li>Novel approaches to address selection bias through wide & deep learning adaptations</li><li>Production deployment serving billions of recommendations with improved user engagement metrics</li></ul><h2 id=1-introduction><strong>1. Introduction</strong></h2><h3 id=11-context--motivation><strong>1.1 Context & Motivation</strong></h3><p><strong>The &ldquo;Watch Next&rdquo; Problem:</strong></p><ul><li><strong>Scenario:</strong> User just finished watching a video, what should they watch next?</li><li><strong>Scale:</strong> Billions of decisions made daily across YouTube&rsquo;s user base</li><li><strong>Complexity:</strong> Multiple objectives must be balanced (engagement, satisfaction, diversity)</li><li><strong>Real-time Constraints:</strong> Recommendations must be generated with low latency</li></ul><p><strong>Evolution from Previous Systems:</strong></p><ul><li>Earlier YouTube systems (2016 DNN paper) focused primarily on single objectives</li><li>Need emerged for multi-objective optimization to improve overall user experience</li><li>Traditional approaches either ignore objective conflicts or use simple linear combinations</li></ul><h3 id=12-challenges-in-multi-objective-recommendation><strong>1.2 Challenges in Multi-Objective Recommendation</strong></h3><p><strong>1.2.1 Objective Conflicts</strong></p><ul><li><strong>Engagement vs. Satisfaction:</strong> High-click content may not lead to user satisfaction</li><li><strong>Short-term vs. Long-term:</strong> Immediately engaging content vs. long-term user retention</li><li><strong>Personalization vs. Diversity:</strong> User preferences vs. content exploration</li></ul><p><strong>1.2.2 Data and Bias Issues</strong></p><ul><li><strong>Selection Bias:</strong> Training data reflects previous recommendation system behavior</li><li><strong>Position Bias:</strong> Items shown in different positions have different exposure</li><li><strong>Feedback Delay:</strong> Some objectives (like satisfaction) have delayed signals</li></ul><p><strong>1.2.3 Production Constraints</strong></p><ul><li><strong>Latency Requirements:</strong> Sub-100ms response times for real-time serving</li><li><strong>Scale:</strong> Billions of candidate videos, millions of concurrent users</li><li><strong>Continuous Learning:</strong> System must adapt to changing user preferences and content</li></ul><h2 id=2-multi-task-learning-architecture><strong>2. Multi-Task Learning Architecture</strong></h2><h3 id=21-problem-formulation><strong>2.1 Problem Formulation</strong></h3><p><strong>Multi-Objective Optimization:</strong></p><ul><li><strong>Primary Objectives:</strong><ul><li>Engagement prediction (clicks, watch time)</li><li>Satisfaction prediction (likes, shares, subscriptions)</li><li>Behavioral prediction (dismissals, not interested signals)</li></ul></li></ul><p><strong>Mathematical Framework:</strong></p><ul><li>Given user-item context features <code>X</code></li><li>Predict multiple targets: <code>Y = {y₁, y₂, ..., yₖ}</code> where each <code>yᵢ</code> represents different objective</li><li>Goal: Learn shared representations while maintaining task-specific adaptations</li></ul><h3 id=22-multi-gate-mixture-of-experts-mmoe><strong>2.2 Multi-gate Mixture-of-Experts (MMoE)</strong></h3><p><strong>2.2.1 Architecture Overview</strong>
<strong>MMoE Components:</strong></p><ol><li><strong>Expert Networks:</strong> <code>E₁, E₂, ..., Eₙ</code> - shared sub-networks that learn different aspects of input space</li><li><strong>Gating Networks:</strong> <code>G₁, G₂, ..., Gₖ</code> - task-specific networks that determine expert importance</li><li><strong>Task Towers:</strong> Task-specific layers that process gated expert outputs</li></ol><p><strong>Mathematical Formulation:</strong></p><pre tabindex=0><code>Expert outputs: eᵢ = Eᵢ(x)
Gate weights for task k: gₖ = Gₖ(x) 
Task input: fₖ = Σᵢ gₖ,ᵢ * eᵢ
Task output: yₖ = Towerₖ(fₖ)
</code></pre><p><strong>2.2.2 Key Advantages Over Alternatives</strong></p><p><strong>Comparison with Shared-Bottom Multi-Task:</strong></p><ul><li><strong>Shared-Bottom:</strong> All tasks share same bottom layers, only final layers are task-specific</li><li><strong>Problem:</strong> When tasks are conflicting, shared representation becomes suboptimal</li><li><strong>MMoE Solution:</strong> Different tasks can attend to different experts based on their needs</li></ul><p><strong>Comparison with Single-Task Models:</strong></p><ul><li><strong>Single-Task:</strong> Separate model for each objective</li><li><strong>Problems:</strong> No knowledge sharing, increased computational cost, parameter inefficiency</li><li><strong>MMoE Solution:</strong> Shared experts capture common patterns while gates enable specialization</li></ul><h3 id=23-expert-and-gate-design><strong>2.3 Expert and Gate Design</strong></h3><p><strong>2.3.1 Expert Networks</strong></p><ul><li><strong>Architecture:</strong> Deep feedforward networks with ReLU activations</li><li><strong>Capacity:</strong> Each expert typically 3-4 layers with 512-1024 units</li><li><strong>Specialization:</strong> Different experts learn to specialize in different input patterns</li><li><strong>Number:</strong> Typically 6-8 experts found optimal through experimentation</li></ul><p><strong>2.3.2 Gating Networks</strong></p><ul><li><strong>Input:</strong> Same features as experts</li><li><strong>Output:</strong> Softmax distribution over experts for each task</li><li><strong>Design:</strong> Lightweight networks (1-2 layers) to avoid overfitting</li><li><strong>Initialization:</strong> Important for training stability</li></ul><p><strong>2.3.3 Task Towers</strong></p><ul><li><strong>Purpose:</strong> Transform gated expert outputs to task-specific predictions</li><li><strong>Architecture:</strong> 2-3 layer feedforward networks</li><li><strong>Output:</strong> Task-specific predictions (probabilities, regression values)</li><li><strong>Loss Functions:</strong> Task-appropriate losses (cross-entropy, mean squared error)</li></ul><h2 id=3-handling-selection-bias><strong>3. Handling Selection Bias</strong></h2><h3 id=31-the-selection-bias-problem><strong>3.1 The Selection Bias Problem</strong></h3><p><strong>Root Cause:</strong></p><ul><li>Training data consists only of user-item pairs that were shown by previous recommendation system</li><li>This creates a feedback loop where model learns to mimic previous system&rsquo;s biases</li><li>Under-representation of certain content types, creators, or user segments</li></ul><p><strong>Impact on Multi-Task Learning:</strong></p><ul><li>Different tasks may have different bias patterns</li><li>Engagement tasks may be biased toward clickbait content</li><li>Satisfaction tasks may miss content that would be satisfying but wasn&rsquo;t recommended</li></ul><h3 id=32-wide--deep-learning-for-bias-correction><strong>3.2 Wide & Deep Learning for Bias Correction</strong></h3><p><strong>3.2.1 Architecture Adaptation</strong>
<strong>Wide Component:</strong></p><ul><li>Linear model with feature crosses</li><li>Memorizes frequent feature combinations from training data</li><li>Captures &ldquo;empirical risk&rdquo; - what the current system shows</li></ul><p><strong>Deep Component:</strong></p><ul><li>Deep neural network (MMoE in this case)</li><li>Learns complex patterns and generalizations</li><li>Captures &ldquo;true risk&rdquo; - underlying user preferences</li></ul><p><strong>3.2.2 Training Strategy</strong></p><ul><li><strong>Wide Part Training:</strong> Focus on accurately modeling observed data distribution</li><li><strong>Deep Part Training:</strong> Regularized to generalize beyond observed distribution</li><li><strong>Joint Training:</strong> Balance between memorization and generalization</li></ul><h3 id=33-additional-bias-mitigation-techniques><strong>3.3 Additional Bias Mitigation Techniques</strong></h3><p><strong>3.3.1 Importance Weighting</strong></p><ul><li>Weight training examples by inverse propensity scores</li><li>Propensity = probability of item being shown given context</li><li>Helps correct for position bias and popularity bias</li></ul><p><strong>3.3.2 Negative Sampling Strategy</strong></p><ul><li><strong>Random Negative Sampling:</strong> Sample items not shown to user</li><li><strong>Hard Negative Mining:</strong> Focus on items similar to positives but not engaged with</li><li><strong>Stratified Sampling:</strong> Ensure representation across different content types</li></ul><h2 id=4-production-system-design><strong>4. Production System Design</strong></h2><h3 id=41-serving-architecture><strong>4.1 Serving Architecture</strong></h3><p><strong>4.1.1 Two-Stage Serving (Building on 2016 System)</strong></p><ul><li><strong>Stage 1:</strong> Candidate generation (unchanged from previous system)</li><li><strong>Stage 2:</strong> Multi-task ranking using MMoE</li><li><strong>Integration:</strong> MMoE model replaces single-task ranking model</li></ul><p><strong>4.1.2 Real-time Feature Engineering</strong></p><ul><li><strong>User Features:</strong> Real-time aggregation of recent user activity</li><li><strong>Item Features:</strong> Video metadata, real-time engagement signals</li><li><strong>Context Features:</strong> Time, device, location, session information</li><li><strong>Cross Features:</strong> User-item interaction features computed on-the-fly</li></ul><h3 id=42-training-infrastructure><strong>4.2 Training Infrastructure</strong></h3><p><strong>4.2.1 Data Pipeline</strong></p><ul><li><strong>Scale:</strong> Processing terabytes of training data daily</li><li><strong>Freshness:</strong> Model retrained multiple times per day with recent data</li><li><strong>Quality:</strong> Extensive data validation and anomaly detection</li></ul><p><strong>4.2.2 Model Training</strong></p><ul><li><strong>Distributed Training:</strong> Parameter servers with hundreds of workers</li><li><strong>Optimization:</strong> Adam optimizer with learning rate scheduling</li><li><strong>Regularization:</strong> Dropout, L2 regularization, early stopping</li><li><strong>Validation:</strong> Holdout validation with temporal splits</li></ul><h3 id=43-ab-testing-and-evaluation><strong>4.3 A/B Testing and Evaluation</strong></h3><p><strong>4.3.1 Online Metrics</strong></p><ul><li><strong>Primary:</strong> Watch time, session length, user retention</li><li><strong>Secondary:</strong> Clicks, likes, shares, subscriptions</li><li><strong>User Experience:</strong> Survey-based satisfaction metrics</li><li><strong>Ecosystem:</strong> Creator metrics, content diversity measures</li></ul><p><strong>4.3.2 Experimental Design</strong></p><ul><li><strong>Controlled Experiments:</strong> Randomized users into treatment/control groups</li><li><strong>Metrics Tracking:</strong> Real-time dashboard for experiment monitoring</li><li><strong>Statistical Testing:</strong> Proper significance testing with multiple comparison corrections</li></ul><h2 id=5-experimental-results><strong>5. Experimental Results</strong></h2><h3 id=51-offline-evaluation><strong>5.1 Offline Evaluation</strong></h3><p><strong>5.1.1 Model Comparison</strong></p><ul><li><strong>Single-Task Baseline:</strong> Separate models for each objective</li><li><strong>Shared-Bottom Multi-Task:</strong> Traditional multi-task learning</li><li><strong>MMoE:</strong> Proposed approach</li></ul><p><strong>Results:</strong></p><ul><li>MMoE significantly outperforms both baselines across all tasks</li><li>Larger improvements on tasks with conflicting objectives</li><li>Better performance stability across different data periods</li></ul><p><strong>5.1.2 Ablation Studies</strong></p><ul><li><strong>Number of Experts:</strong> 6-8 experts optimal, diminishing returns beyond 8</li><li><strong>Expert Architecture:</strong> Deeper experts (4 layers) better than wider experts</li><li><strong>Gate Architecture:</strong> Simple gates (1-2 layers) sufficient and more stable</li></ul><h3 id=52-online-evaluation><strong>5.2 Online Evaluation</strong></h3><p><strong>5.2.1 User Engagement Metrics</strong></p><ul><li><strong>Watch Time:</strong> +X% improvement in total watch time per user</li><li><strong>Session Length:</strong> +Y% increase in average session duration</li><li><strong>User Retention:</strong> +Z% improvement in day-7 retention rate</li></ul><p><strong>5.2.2 Multi-Objective Balance</strong></p><ul><li><strong>Engagement vs. Satisfaction:</strong> Better balance achieved compared to single-objective optimization</li><li><strong>Short-term vs. Long-term:</strong> Improved long-term user retention without sacrificing immediate engagement</li><li><strong>Personalization vs. Diversity:</strong> Better content diversity while maintaining personalization quality</li></ul><h3 id=53-bias-mitigation-results><strong>5.3 Bias Mitigation Results</strong></h3><ul><li><strong>Content Diversity:</strong> Increased representation of diverse content types</li><li><strong>Creator Fairness:</strong> More equitable exposure across different creator segments</li><li><strong>User Satisfaction:</strong> Survey metrics show improved user satisfaction with recommendations</li></ul><h2 id=6-lessons-learned-and-best-practices><strong>6. Lessons Learned and Best Practices</strong></h2><h3 id=61-multi-task-learning-insights><strong>6.1 Multi-Task Learning Insights</strong></h3><ul><li><strong>Task Relatedness:</strong> MMoE works best when tasks share some common patterns but also have conflicts</li><li><strong>Expert Specialization:</strong> Visualization shows experts specialize in different user segments and content types</li><li><strong>Gate Interpretability:</strong> Gate weights provide insights into which experts are important for which tasks</li></ul><h3 id=62-production-deployment-lessons><strong>6.2 Production Deployment Lessons</strong></h3><ul><li><strong>Gradual Rollout:</strong> Incremental deployment crucial for large-scale systems</li><li><strong>Monitoring:</strong> Comprehensive monitoring essential for multi-objective systems</li><li><strong>Debugging:</strong> Multi-task models harder to debug; need task-specific analysis tools</li></ul><h3 id=63-bias-mitigation-learnings><strong>6.3 Bias Mitigation Learnings</strong></h3><ul><li><strong>Data Quality:</strong> High-quality bias mitigation requires careful data curation</li><li><strong>Multiple Approaches:</strong> Combining multiple bias mitigation techniques more effective than single approach</li><li><strong>Continuous Monitoring:</strong> Bias patterns change over time, requiring ongoing attention</li></ul><h2 id=7-impact-and-significance><strong>7. Impact and Significance</strong></h2><h3 id=71-academic-contributions><strong>7.1 Academic Contributions</strong></h3><ul><li><strong>MMoE Architecture:</strong> Novel architecture that balances sharing and specialization</li><li><strong>Production Multi-Task Learning:</strong> Demonstrates multi-task learning at unprecedented scale</li><li><strong>Bias Mitigation:</strong> Practical approaches to handling selection bias in recommender systems</li></ul><h3 id=72-industry-impact><strong>7.2 Industry Impact</strong></h3><ul><li><strong>Multi-Objective Optimization:</strong> Established new standard for recommendation system objectives</li><li><strong>Architecture Pattern:</strong> MMoE architecture adopted by other platforms</li><li><strong>Production Best Practices:</strong> Influenced deployment strategies for large-scale ML systems</li></ul><h3 id=73-research-directions-enabled><strong>7.3 Research Directions Enabled</strong></h3><ul><li><strong>Mixture of Experts:</strong> Renewed interest in MoE architectures for various applications</li><li><strong>Multi-Task Learning:</strong> Advanced research in task relationship modeling</li><li><strong>Bias and Fairness:</strong> Increased focus on bias mitigation in recommendation systems</li></ul><h2 id=8-future-work-and-limitations><strong>8. Future Work and Limitations</strong></h2><h3 id=81-current-limitations><strong>8.1 Current Limitations</strong></h3><ul><li><strong>Scalability:</strong> Expert multiplication can lead to parameter explosion</li><li><strong>Task Addition:</strong> Adding new tasks requires architectural changes</li><li><strong>Interpretability:</strong> Complex gating patterns difficult to interpret</li></ul><h3 id=82-potential-improvements><strong>8.2 Potential Improvements</strong></h3><ul><li><strong>Dynamic Expert Allocation:</strong> Adaptive number of experts based on task complexity</li><li><strong>Hierarchical Multi-Task:</strong> Organizing tasks in hierarchical structures</li><li><strong>Meta-Learning:</strong> Learning to adapt quickly to new tasks or objectives</li></ul><h3 id=83-emerging-challenges><strong>8.3 Emerging Challenges</strong></h3><ul><li><strong>Fairness:</strong> Ensuring fair treatment across user groups and content creators</li><li><strong>Privacy:</strong> Balancing personalization with user privacy requirements</li><li><strong>Transparency:</strong> Making recommendation decisions more explainable to users</li></ul><hr><p><strong>Personal Notes:</strong>
This paper represents a significant evolution in recommendation systems, moving from single-objective to multi-objective optimization at scale. The MMoE architecture has become influential not just in recommendations but in multi-task learning generally. The practical focus on bias mitigation and production deployment makes this especially valuable for practitioners working on real-world systems.</p></div><hr><div class=paper-reference><p><strong>Read the original paper:</strong>
<a href=https://daiwk.github.io/assets/youtube-multitask.pdf target=_blank rel="noopener noreferrer">Recommending What Video to Watch Next: A Multitask Ranking System</a></p><p class=paper-disclaimer><em>The content presented here is a collection of my personal notes and explanations based on the paper. This is by no means an exhaustive explanation, and I strongly encourage you to read the actual paper for a comprehensive understanding.</em></p></div></article></div></main><footer><p>&copy; 2025 Deepanshu Kandpal</p></footer><a id=scrollTopBtn title="Go to top"><i class="fa-solid fa-arrow-up"></i></a>
<script src=/js/search.js></script><script>var mybutton=document.getElementById("scrollTopBtn");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?mybutton.classList.add("show"):mybutton.classList.remove("show")}mybutton.onclick=function(){document.body.scrollTop=0,document.documentElement.scrollTop=0}</script><script>document.addEventListener("DOMContentLoaded",function(){const e=document.querySelectorAll("code.language-mermaid");e.forEach(function(e,t){const n=document.createElement("div");n.className="mermaid",n.textContent=e.textContent,n.id="mermaid-"+t,e.parentNode.parentNode.replaceChild(n,e.parentNode)}),mermaid.initialize({startOnLoad:!0,theme:"default",themeVariables:{primaryColor:"#4a90e2",primaryTextColor:"#333",primaryBorderColor:"#4a90e2",lineColor:"#333"}}),mermaid.init()})</script></body></html>